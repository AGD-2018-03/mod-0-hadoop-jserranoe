{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop/MapReduce -- WordCount en Java (Modo Standalone)\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del problema\n",
    "\n",
    "Se desea contar la frecuencia de ocurrencia de palabras en un conjunto de documentos. Debido a los requerimientos de diseño (gran volúmen de datos y tiempos rápidos de respuesta) se desea implementar una arquitectura Big Data. **Se desea probar el código en la máquina local. El código debe ser escrito en Java.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se generarán tres archivos de prueba para probar el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepara el directorio de trabajo\n",
    "!rm -rf input output\n",
    "!mkdir input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text0.txt\n",
    "Analytics Analytics is the discovery, interpretation, and communication of meaningful patterns \n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies \n",
    "on the simultaneous application of statistics, computer programming and operations research \n",
    "to quantify performance pailas.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business \n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive \n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big \n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization, \n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech \n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive \n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive \n",
    "computation (see big data), the algorithms and software used for analytics harness the most \n",
    "current methods in computer science, statistics, and mathematics pailas pailas repailas consiampipailas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to \n",
    "research potential trends, to analyze the effects of certain decisions or events, or to \n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve \n",
    "the business by gaining knowledge which can be used to make improvements or changes pailas pailas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions \n",
    "about the information they contain, increasingly with the aid of specialized systems \n",
    "and software. Data analytics technologies and techniques are widely used in commercial \n",
    "industries to enable organizations to make more-informed business decisions and by \n",
    "scientists and researchers to verify or disprove scientific models, theories and \n",
    "hypotheses pailas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tutorial detallado se encuentra en http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial se planteará la solución en Java. Para construir una aplicación que usa MapReduce, el usuario debe implementar la función map y la función reduce; el sistema se encarga por si solo de ejecutarlas en el cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1\n",
    "\n",
    "Se implementa el algoritmo de conteo de palabras y se guarda en el archivo `WordCount.java`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCount.java\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCount.java\n",
    "\n",
    "import java.io.IOException;\n",
    "\n",
    "/*\n",
    " * Esta clase permite separar una frase (texto)\n",
    " * en las palabras que lo conforman. La lista\n",
    " * resultante puede ser iterada en un ciclo for\n",
    " */\n",
    "import java.util.StringTokenizer;\n",
    "\n",
    "/*\n",
    " *\n",
    " * Librerias requeridas para ejecutar Hadoop\n",
    " *\n",
    " */\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "\n",
    "/*\n",
    " * Esta clase implementa el mapper y el reducer\n",
    " */\n",
    "public class WordCount {\n",
    "\n",
    "  public static class TokenizerMapper\n",
    "       extends Mapper<Object, Text, Text, IntWritable>{\n",
    "       \n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "\n",
    "    /* \n",
    "     * en esta variable se guarda cada palabra leida        \n",
    "     * del flujo de entrada\n",
    "     */     \n",
    "    private Text word = new Text();\n",
    "\n",
    "    /* \n",
    "     * Este es el mapper. Para cada palabra \n",
    "     * leída, emite el par <word, 1>\n",
    "     */\n",
    "    public void map(Object key,       // Clave\n",
    "                    Text value,       // La linea de texto\n",
    "                    Context context   // Aplicación que se esta ejecutando\n",
    "                    ) throws IOException, InterruptedException {\n",
    "                              \n",
    "      // Convierte la línea de texto en una lista de strings\n",
    "      StringTokenizer itr = new StringTokenizer(value.toString());\n",
    "                              \n",
    "      // Ejecuta el ciclo para cada palabra \n",
    "      // de la lista de strings\n",
    "      while (itr.hasMoreTokens()) {\n",
    "        // obtiene la palabra\n",
    "        word.set(itr.nextToken());\n",
    "\n",
    "        // escribe la pareja <word, 1> \n",
    "        // al flujo de salida\n",
    "        context.write(word, one);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  public static class IntSumReducer\n",
    "       extends Reducer<Text,IntWritable,Text,IntWritable> {\n",
    "           \n",
    "    // Clase para imprimir un entero al flujo de salida       \n",
    "    private IntWritable result = new IntWritable();\n",
    "\n",
    "    // Esta función es llamada para reducir \n",
    "    // una lista de valores que tienen la misma clave\n",
    "    public void reduce(Text key,                      // clave\n",
    "                       Iterable<IntWritable> values,  // lista de valores\n",
    "                       Context context                // Aplicación que se esta ejecutando\n",
    "                       ) throws IOException, InterruptedException {\n",
    "        \n",
    "      // itera sobre la lista de valores, sumandolos\n",
    "      int sum = 0;\n",
    "      for (IntWritable val : values) {\n",
    "        sum += val.get();\n",
    "      }\n",
    "      result.set(sum);\n",
    "        \n",
    "      // escribe la pareja <word, valor> al flujo\n",
    "      // de salida\n",
    "      context.write(key, result);\n",
    "    }\n",
    "  }\n",
    "\n",
    "    \n",
    "  /*\n",
    "   * Se crea la aplicación en Hadoop y se ejecuta\n",
    "   */\n",
    "  public static void main(String[] args) throws Exception {\n",
    "    Configuration conf = new Configuration();\n",
    "    \n",
    "    /*\n",
    "     * El job corresponde a la aplicacion\n",
    "     */\n",
    "    Job job = Job.getInstance(conf, \"word count\");\n",
    "      \n",
    "    /*\n",
    "     * La clase que contiene el mapper y el reducer\n",
    "     */\n",
    "    job.setJarByClass(WordCount.class);\n",
    "      \n",
    "    /* \n",
    "     * Clase que implementa el mapper  \n",
    "     */ \n",
    "    job.setMapperClass(TokenizerMapper.class);\n",
    "      \n",
    "    /*\n",
    "     * El combiner es un reducer que se coloca a la salida\n",
    "     * del mapper para agilizar el computo\n",
    "     */\n",
    "    job.setCombinerClass(IntSumReducer.class);\n",
    "    \n",
    "    /*\n",
    "     * Clase que implementa el reducer\n",
    "     */\n",
    "    job.setReducerClass(IntSumReducer.class);\n",
    "      \n",
    "    /*\n",
    "     * Salida\n",
    "     */\n",
    "    job.setOutputKeyClass(Text.class);\n",
    "    job.setOutputValueClass(IntWritable.class);\n",
    "    \n",
    "    /*\n",
    "     * Formatos de entrada y salida\n",
    "     */\n",
    "    FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "   \n",
    "    // resultado de la ejecución.\n",
    "    System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "  }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2\n",
    "Se realiza la compilación del programa. Para que el programa se ejecute correctamente, se debió definir la variable de entorno `$HADOOP_HOME`, la cual apunta al directorio donde se encuentra Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$HADOOP_HOME/bin/hadoop com.sun.tools.javac.Main WordCount.java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3\n",
    "\n",
    "Se genera el archivo de aplicación de Java, para luego ejecutarlo usando Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jar cf wc.jar WordCount*.class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo `wc.jar` debe aparecer en el directorio actua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc.jar\r\n"
     ]
    }
   ],
   "source": [
    "!ls *.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4\n",
    "\n",
    "En este tutorial se usará el modo *standalone*, en el que la máquina virtual de Java se ejecuta en un único hilo de procesamiento. Este modo es utilizado para depurar programas. En este modo, solo se requiere que no haya ninguna especificación en `<configuration>` ... `</configuration>` de los archivos `etc/hadoop/core-site.xml`  y `etc/hadoop/hdfs-site.xml` que se encuentran en el directorio de instalación de Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<EOF > $HADOOP_HOME/etc/hadoop/core-site.xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
    "<configuration>\n",
    "</configuration>\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<\\EOF > $HADOOP_HOME/etc/hadoop/hdfs-site.xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
    "<configuration>\n",
    "</configuration>\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5\n",
    "\n",
    "Se eejecuta el programa para realizar el conteo de palabras. En el modo *standalone*, los directorios de entrada (`input/`) y salida (`output/`) se encuentran en la carpeta actual donde se abrio Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ejecuta el proceso para los archivos \n",
    "## de texto en el directorio input\n",
    "## Se puede usar la opción --loglevel {OFF, FATAL, ERROR, WARN, DEBUG, INFO, TRACE, ALL} asi:\n",
    "##\n",
    "##         !$HADOOP_HOME/bin/hadoop --loglevel ERROR jar wc.jar WordCount input output \n",
    "##\n",
    "## o modificar el archivo .bash_profile con la variable de entorno\n",
    "##\n",
    "##   export HADOOP_ROOT_LOGGER=\"ERROR,console\"\n",
    "##\n",
    "!$HADOOP_HOME/bin/hadoop jar wc.jar WordCount input output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6\n",
    "La salida del paso anterior se revisa para determinar si hay algún mensaje de error. Si el proceso se ejecutó correctamente, el directorio `ouput/` contiene el resultado de la ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-r-00000  _SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "## contenido el directorio de salida\n",
    "!ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DA)\t1\r\n",
      "(see\t1\r\n",
      "Analytics\t3\r\n",
      "Analytics,\t1\r\n",
      "Big\t1\r\n",
      "Data\t3\r\n",
      "Especially\t1\r\n",
      "Organizations\t1\r\n",
      "Since\t1\r\n",
      "Specifically,\t1\r\n",
      "The\t2\r\n",
      "a\t1\r\n",
      "about\t1\r\n",
      "aid\t1\r\n",
      "algorithms\t1\r\n",
      "analysis,\t1\r\n",
      "analysis.\t1\r\n",
      "analytics\t8\r\n",
      "analytics,\t8\r\n",
      "analytics.\t1\r\n",
      "analyze\t1\r\n",
      "and\t15\r\n",
      "application\t1\r\n",
      "apply\t1\r\n",
      "are\t1\r\n",
      "areas\t2\r\n",
      "assortment\t1\r\n",
      "be\t1\r\n",
      "big\t1\r\n",
      "business\t4\r\n",
      "by\t2\r\n",
      "call\t1\r\n",
      "can\t2\r\n",
      "certain\t1\r\n",
      "changes\t1\r\n",
      "cognitive\t1\r\n",
      "commercial\t1\r\n",
      "communication\t1\r\n",
      "computation\t1\r\n",
      "computer\t2\r\n",
      "conclusions\t1\r\n",
      "consiampipailas.\t1\r\n",
      "contain,\t1\r\n",
      "credit\t1\r\n",
      "current\t1\r\n",
      "data\t4\r\n",
      "data),\t1\r\n",
      "data.\t1\r\n",
      "decision\t1\r\n",
      "decisions\t2\r\n",
      "describe,\t1\r\n",
      "descriptive\t1\r\n",
      "discovery,\t1\r\n",
      "disprove\t1\r\n",
      "draw\t1\r\n",
      "effects\t1\r\n",
      "enable\t1\r\n",
      "enterprise\t1\r\n",
      "evaluate\t1\r\n",
      "events,\t1\r\n",
      "examining\t1\r\n",
      "extensive\t1\r\n",
      "field\t1\r\n",
      "for\t1\r\n",
      "force\t1\r\n",
      "fraud\t1\r\n",
      "gaining\t1\r\n",
      "given\t1\r\n",
      "goal\t1\r\n",
      "harness\t1\r\n",
      "historical\t1\r\n",
      "hypotheses\t1\r\n",
      "improve\t2\r\n",
      "improvements\t1\r\n",
      "in\t5\r\n",
      "include\t1\r\n",
      "increasingly\t1\r\n",
      "industries\t1\r\n",
      "information\t1\r\n",
      "information,\t1\r\n",
      "interpretation,\t1\r\n",
      "involves\t1\r\n",
      "is\t3\r\n",
      "knowledge\t1\r\n",
      "make\t2\r\n",
      "management,\t1\r\n",
      "marketing\t2\r\n",
      "mathematics\t1\r\n",
      "may\t1\r\n",
      "meaningful\t1\r\n",
      "methods\t1\r\n",
      "mix\t1\r\n",
      "modeling,\t2\r\n",
      "models,\t1\r\n",
      "more-informed\t1\r\n",
      "most\t1\r\n",
      "of\t8\r\n",
      "often\t1\r\n",
      "on\t1\r\n",
      "operations\t1\r\n",
      "optimization\t1\r\n",
      "optimization,\t2\r\n",
      "or\t5\r\n",
      "order\t1\r\n",
      "organizations\t1\r\n",
      "pailas\t3\r\n",
      "pailas.\t3\r\n",
      "past\t1\r\n",
      "patterns\t1\r\n",
      "performance\t2\r\n",
      "performance.\t1\r\n",
      "potential\t1\r\n",
      "predict,\t1\r\n",
      "predictive\t2\r\n",
      "prescriptive\t1\r\n",
      "price\t1\r\n",
      "process\t1\r\n",
      "programming\t1\r\n",
      "promotion\t1\r\n",
      "quantify\t1\r\n",
      "recorded\t1\r\n",
      "relies\t1\r\n",
      "repailas\t1\r\n",
      "require\t1\r\n",
      "research\t2\r\n",
      "researchers\t1\r\n",
      "retail\t1\r\n",
      "rich\t1\r\n",
      "risk\t1\r\n",
      "sales\t1\r\n",
      "scenario.\t1\r\n",
      "science,\t2\r\n",
      "scientific\t1\r\n",
      "scientists\t1\r\n",
      "sets\t1\r\n",
      "simultaneous\t1\r\n",
      "sizing\t1\r\n",
      "software\t1\r\n",
      "software.\t1\r\n",
      "specialized\t1\r\n",
      "speech\t1\r\n",
      "statistics,\t2\r\n",
      "stock-keeping\t1\r\n",
      "store\t1\r\n",
      "studying\t1\r\n",
      "systems\t1\r\n",
      "techniques\t1\r\n",
      "technologies\t1\r\n",
      "the\t10\r\n",
      "theories\t1\r\n",
      "they\t1\r\n",
      "to\t12\r\n",
      "tool\t1\r\n",
      "trends,\t1\r\n",
      "unit\t1\r\n",
      "used\t3\r\n",
      "valuable\t1\r\n",
      "verify\t1\r\n",
      "web\t1\r\n",
      "which\t1\r\n",
      "widely\t1\r\n",
      "with\t2\r\n",
      "within\t1\r\n"
     ]
    }
   ],
   "source": [
    "## imprime el resultado en pantalla\n",
    "!cat output/part-r-00000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Ejercicio.--** Cómo se puede ejecutar el conteo de palabras únicamente para el archivo `text0.txt`?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## se limpia el directoroio de trabajo\n",
    "!rm WordCount*.* *.jar\n",
    "!rm -rf input output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
